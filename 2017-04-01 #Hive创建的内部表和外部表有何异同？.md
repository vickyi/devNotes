## Hive创建的内部表和外部表有何异同？


这个其实和很多传统数据库中的内部表和外部表一样，没有什么差别。

从表的创建和删除两方面简单介绍一下：
1. Hive 创建内部表时，后面执行导入操作时会将用户数据移动到表所在的数据仓库指向的路径；
2. 若创建外部表时，只会记录表对应的用户数据所在的路径，不对用户数据的位置做任何改变。
3. 在删除表的时候，内部表的元数据和用户数据会被一起删除；
4. 而外部表只会删除元数据，不删除用户数据。这样外部表相对来说更加安全些，数据组织也更加灵活，方便共享源数据。
5. 


## Hive的优化技巧有哪些？比如如何处理数据倾斜、大表与小表join时，如何优化性能？

Hive优化其实涉及到几方面，其中一方面是计算引擎方面的优化，比如你使用MapReduce作为计算引擎，那么就需要优化MapReduce；如果你选择Spark作为计算引擎，那么需要对Spark进行优化。

这里仅从Hive这一层面介绍该如何优化，基本内容如下：
### 表设计层面优化
- 合理利用中间结果集，避免查过就丢的资源浪费，减低Hadoop的IO负载
- 合理设计表分区，包括静态分区和动态分区
- 尽量不使用复杂或低效函数，比如count(distinct)，可以使用其他方式实现
- 选择合适的表存储格式和压缩格式
- 如果某些逻辑使用系统函数可能嵌套好几层，那么可以使用自定义函数实现
- 适当使用索引
### 语法和参数层面优化
- 合理控制mapper和reducer数
- 设置map和reduce的内存大小
- 合并小文件
- 避免数据倾斜，解决数据倾斜问题
　　处理数据倾斜的方法其实有很多，不论是Group by还是Join时出现数据倾斜，其实都是数据热点的问题，即某些Key值太多，导致都分发到一个节点执行，那么我们可以将数据量比较大的Key拿出来单独处理，最后再合并到结果集中。如果出现数据倾斜的Key值对结果无关紧要，比如空值，那么我们可以过滤处理，或者将空值加上随机数，进行分发到集群的所有节点并行处理。当然也可以利用Hive自带的参数进行优化，设置当分组或关联的Key值超过多少数量时，进行单独处理，即额外启动一个MapReduce作业处理。
　　
- 减少Job数
- Join优化
　　尽量将小表放到join的左边。小表和大表join时，如果差一个以及以上数量级并且小表数据量很小，可以使用mapjoin方式，将小表全部读入内存中，在map阶段进行表关联匹配。大表和大表进行关联时，要注意数据倾斜的问题。如果两个表以相同Key进行分桶，以及表的桶个数是倍数关系，可以使用bucket join，加快关联查询。
避免笛卡尔积
提前裁剪数据，减少处理的数据量，避免资源浪费
### 3)Hive Job优化
- 并行化执行——每个查询被Hive转化成多个阶段，有些阶段关联性不大，则可以并行化执行，减少执行时间。
- 本地化执行
- JVM重利用——JVM重利用可以是Job长时间保留slot，直到作业结束，这在对于有较多任务和较多小文件的任务是非常有意义的，减少执行时间。
- 推测执行——所谓的推测执行，就是当所有的task都开始运行之后，Job Tracker会统计所有任务的平均进度，如果某个task所在的节点配置内存比较低或者CPU负载很大，导致任务执行比总体任务的平均执行要慢，此时Job Tracker就会在其他节点启动一个新的相同的任务，原有任务和新任务哪个先执行完就把其他节点的另外一个任务kill掉。
- Hive中间结果压缩数据——中间压缩就是处理Hive查询的多个job之间的数据，对于中间压缩，最好选择一个节省CPU耗时的压缩方式